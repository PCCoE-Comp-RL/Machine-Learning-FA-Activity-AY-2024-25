# -*- coding: utf-8 -*-
"""house_rentals_predictions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ACFTPfGKQQNOG2tA7Sc9c5YtBK7eIuht
"""

from google.colab import files
uploaded = files.upload()

# Step 2: Load the dataset
import pandas as pd

df = pd.read_csv('BangaloreHouseRentDtls.csv')
df.head()

df.info()
df.describe()
df.isnull().sum()

# Step 1: Drop rows with missing values (if any)
df.dropna(inplace=True)

# Optional: Print column names to verify structure
print(df.columns)

print(df.columns)

# List all columns in your dataset
print("Columns in dataset:", df.columns.tolist())

# Only include columns that exist in your file
categorical_columns = []

if 'Location' in df.columns:
    categorical_columns.append('Location')
if 'Area Type' in df.columns:
    categorical_columns.append('Area Type')

# Encode categorical columns only if they exist
if categorical_columns:
    df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)
else:
    print("No categorical columns to encode.")

# Step 1: Drop rows with missing values (if any)

# Check if 'Size' column exists before dropping rows based on it
if 'Size' in df.columns:
    df.dropna(subset=['Size'], inplace=True)  # Drop rows with missing values ONLY in 'Size' column
else:
    print("Column 'Size' not found in the DataFrame. It might have been removed during previous operations.")

# Optional: Print column names to verify structure
print(df.columns)

from sklearn.preprocessing import LabelEncoder

# Initialize LabelEncoder
le = LabelEncoder()

# Encode 'Locality' and 'HouseType'
df['Locality_encoded'] = le.fit_transform(df['Locality'])
df['HouseType_encoded'] = le.fit_transform(df['HouseType'])

# Drop original categorical columns (optional)
df.drop(['Locality', 'HouseType'], axis=1, inplace=True)

# Check the dataframe
df.head()

# Features (independent variables)
X = df.drop('AvgRent', axis=1)

# Target (dependent variable)
y = df['AvgRent']

from sklearn.model_selection import train_test_split

# 80% training, 20% testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(X_train.shape)
print(y_train.shape)
print(X_train.head())

import pandas as pd

# Assuming df is your DataFrame

# Function to clean the 'Size' column and convert it to numerical values
def clean_size(size_str):
    if isinstance(size_str, str):  # Check if it's a string
        try:
            # Split the string by space and take the first part
            # Assuming size is the first part (e.g., '1.1' in '1.1 L')
            size_num = float(size_str.split()[0])
            return size_num
        except (ValueError, IndexError):
            # Handle cases where conversion fails or format is unexpected
            # You might want to log these errors or handle them differently
            print(f"Error processing size: {size_str}")
            return None  # Or a default value
    else:
        return size_str  # If not a string, return as is

# Check if 'Size' column exists before applying the function
if 'Size' in df.columns:
    # Apply the cleaning function to the 'Size' column
    df['Size'] = df['Size'].apply(clean_size)

    # Drop rows with any missing values in 'Size' (if introduced by cleaning)
    df.dropna(subset=['Size'], inplace=True)
else:
    print("Column 'Size' not found in the DataFrame. Skipping cleaning.")

# ... (rest of your code)

print(X_train.columns)

if 'Size' in df.columns:
    df.drop(['Size'], axis=1, inplace=True)

# Re-split features and target
X = df.drop(['AvgRent'], axis=1)
y = df['AvgRent']

# One-hot encode categorical columns
X_encoded = pd.get_dummies(X)

# Train-test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Train the model
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

# Predict and evaluate
y_pred = lin_reg.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Linear Regression Results:")
print("Mean Squared Error:", mse)
print("R¬≤ Score:", r2)

from sklearn.metrics import mean_squared_error
import numpy as np

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print("Root Mean Squared Error:", rmse)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Evaluate the Linear Regression model
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

# Print all metrics
print("Linear Regression Model Evaluation:")
print(f"R¬≤ Score: {r2}")
print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")

from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

# Initialize scalers
scaler_X = StandardScaler()
scaler_y = StandardScaler()

# Fit and transform training data
X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)

y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()
y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()

from sklearn.svm import SVR

# Initialize and train the SVR model
svr_model = SVR(kernel='rbf')  # You can try 'linear' or 'poly' too
svr_model.fit(X_train_scaled, y_train_scaled)

# Predict on test data
y_pred_scaled = svr_model.predict(X_test_scaled)

# Inverse transform predictions back to original scale
y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Evaluation metrics
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

# Print the results
print("SVR Model Evaluation:")
print(f"R¬≤: {r2}")
print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")
print(f"Root Mean Squared Error: {rmse}")

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Evaluation metrics
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

# Print the results
print("Random Forest Model Evaluation:")
print(f"R¬≤: {r2}")
print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")
print(f"Root Mean Squared Error: {rmse}")

!pip install xgboost
import xgboost as xgb

from xgboost import XGBRegressor

# Initialize the model
xgb_model = XGBRegressor(random_state=42)

# Train the model
xgb_model.fit(X_train, y_train)

# Predict on test set
y_pred = xgb_model.predict(X_test)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Evaluation metrics
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

# Print the results
print("XGBoost Model Evaluation:")
print(f"R¬≤: {r2}")
print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")
print(f"Root Mean Squared Error: {rmse}")

!pip install catboost
from catboost import CatBoostRegressor

# Initialize the model
cat_model = CatBoostRegressor(verbose=0, random_state=42)

# Train the model
cat_model.fit(X_train, y_train)

# Predict on test set
y_pred = cat_model.predict(X_test)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Evaluation metrics
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

# Print the results
print("CatBoost Model Evaluation:")
print(f"R¬≤: {r2}")
print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")
print(f"Root Mean Squared Error: {rmse}")

y_pred_cat = cat_model.predict(X_test)

y_pred_cat = cat_model.predict(X_test)

y_pred_xgb = xgb_model.predict(X_test)

from sklearn.ensemble import RandomForestRegressor

# Create and train the Random Forest model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predict on the test set
y_pred_rf = rf_model.predict(X_test)

# Limit to top 15 features
top_n = 15
feature_imp_rf_top = feature_imp_rf.head(top_n)

plt.figure(figsize=(8, 5))
sns.barplot(x='Importance', y='Feature', data=feature_imp_rf_top, palette='Greens_r')
plt.title(f'Random Forest - Top {top_n} Feature Importances')
plt.tight_layout()
plt.show()

# Assuming you already have xgb_model trained and X_train defined
importances_xgb = xgb_model.feature_importances_
feature_names = X_train.columns

feature_imp_xgb = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances_xgb
}).sort_values(by='Importance', ascending=False).head(15)

plt.figure(figsize=(8, 5))
sns.barplot(x='Importance', y='Feature', data=feature_imp_xgb, palette='Oranges_r')
plt.title('XGBoost - Top 15 Feature Importances')
plt.tight_layout()
plt.show()

# Assuming you already have cat_model trained and X_train defined
importances_cat = cat_model.get_feature_importance()
feature_names = X_train.columns

feature_imp_cat = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances_cat
}).sort_values(by='Importance', ascending=False).head(15)

plt.figure(figsize=(8, 5))
sns.barplot(x='Importance', y='Feature', data=feature_imp_cat, palette='Blues_r')
plt.title('CatBoost - Top 15 Feature Importances')
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Get feature importances from the Random Forest model
importances = rf_model.feature_importances_

# Ensure number of features matches
print("Length of importances:", len(importances))
print("Length of X.columns:", len(X.columns))
print("Feature names:", list(X.columns))

# Create the DataFrame safely
if len(importances) == len(X.columns):
    feature_imp_df = pd.DataFrame({
        'Feature': X.columns,
        'Importance': importances
    })

    # Sort and plot
    feature_imp_df.sort_values(by='Importance', ascending=False, inplace=True)

    plt.figure(figsize=(10, 6))
    sns.barplot(x='Importance', y='Feature', data=feature_imp_df, palette='viridis')
    plt.title('Feature Importance (Random Forest)')
    plt.xlabel('Importance')
    plt.ylabel('Feature')
    plt.tight_layout()
    plt.show()
else:
    print("Mismatch in feature names and importances. Please check the feature set (X) and model.")

print("Number of columns in X:", len(X.columns))
print("Number of coefficients in Linear Regression model:", len(lin_reg.coef_))

# Take absolute value of coefficients for plotting
lin_importance_df = pd.DataFrame({
    'Feature': X_train.columns,
    'Coefficient': np.abs(lin_reg.coef_)
}).sort_values(by='Coefficient', ascending=False)

# Plot Top 15 important features (positive only)
plt.figure(figsize=(10, 6))
sns.barplot(data=lin_importance_df.head(15), x='Coefficient', y='Feature', palette='Blues_r')
plt.title('Top 15 Important Features - Linear Regression')
plt.xlabel('Absolute Coefficient Value')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()

from sklearn.metrics import r2_score

# Example assuming you already have these prediction variables:
# y_pred_lin, y_pred_svr, y_pred_rf, y_pred_xgb, y_pred_cat

# Make sure y_test is a flat Series
y_test_series = y_test.iloc[:, 0] if isinstance(y_test, pd.DataFrame) else y_test

# Compute R¬≤ scores
r2_lin = r2_score(y_test_series, y_pred_lin)
r2_svr = r2_score(y_test_series, y_pred_svr)
r2_rf = r2_score(y_test_series, y_pred_rf)
r2_xgb = r2_score(y_test_series, y_pred_xgb)
r2_cat = r2_score(y_test_series, y_pred_cat)

# Model Comparison Plot
models = ['Linear Regression', 'SVR', 'Random Forest', 'XGBoost', 'CatBoost']
r2_scores = [r2_lin, r2_svr, r2_rf, r2_xgb, r2_cat]

plt.figure(figsize=(10, 5))
bars = plt.bar(models, r2_scores, color='teal', edgecolor='black')

# Add value labels
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f"{yval:.2f}", ha='center', va='bottom')

plt.title("Model Comparison (R¬≤ Score)")
plt.ylabel("R¬≤ Score")
plt.ylim(0, 1.1)
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.histplot(data=df, x="AvgRent", kde=True, bins=50, color='mediumseagreen')

plt.title("Distribution of Target Variable (AvgRent)")
plt.xlabel("Rent")
plt.ylabel("Frequency")

# Show every 10th tick and rotate
plt.xticks(ticks=plt.xticks()[0][::10], rotation=45)

plt.tight_layout()
plt.show()

print("R¬≤ Scores:")
print("Linear Regression:", r2_lin)
print("SVR:", r2_svr)
print("Random Forest:", r2_rf)
print("XGBoost:", r2_xgb)
print("CatBoost:", r2_cat)

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np
import pandas as pd

# Ensure y_test is a Series
y_test_series = y_test.iloc[:, 0] if isinstance(y_test, pd.DataFrame) else y_test

# Define a helper function
def get_metrics(y_true, y_pred):
    return {
        'R¬≤ Score': r2_score(y_true, y_pred),
        'MAE': mean_absolute_error(y_true, y_pred),
        'MSE': mean_squared_error(y_true, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred))
    }

# Get metrics for each model
results = {
    'Linear Regression': get_metrics(y_test_series, y_pred_lin),
    'SVR': get_metrics(y_test_series, y_pred_svr),
    'Random Forest': get_metrics(y_test_series, y_pred_rf),
    'XGBoost': get_metrics(y_test_series, y_pred_xgb),
    'CatBoost': get_metrics(y_test_series, y_pred_cat)
}

# Create DataFrame
results_df = pd.DataFrame(results).T  # Transpose to have models as rows

# Optional: round values
results_df = results_df.round(3)

# Display table
display(results_df)

from sklearn.metrics import mean_squared_error
import numpy as np
import pandas as pd

# Ensure y_test is a Series
y_test_series = y_test.iloc[:, 0] if isinstance(y_test, pd.DataFrame) else y_test

# Function to compute RMSE and MSE
def get_rmse_mse(y_true, y_pred):
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    return {'MSE': mse, 'RMSE': rmse}

# Calculate for all models
comparison = {
    'Linear Regression': get_rmse_mse(y_test_series, y_pred_lin),
    'SVR': get_rmse_mse(y_test_series, y_pred_svr),
    'Random Forest': get_rmse_mse(y_test_series, y_pred_rf),
    'XGBoost': get_rmse_mse(y_test_series, y_pred_xgb),
    'CatBoost': get_rmse_mse(y_test_series, y_pred_cat)
}

# Convert to DataFrame
comparison_df = pd.DataFrame(comparison).T.round(2)

# Display
display(comparison_df)

# MSE Bar Chart
plt.figure(figsize=(10, 5))
plt.bar(comparison_df.index, comparison_df['MSE'], color='cornflowerblue', edgecolor='black')

# Add values on top
for i, v in enumerate(comparison_df['MSE']):
    plt.text(i, v + 0.01 * v, f"{v:,.0f}", ha='center', va='bottom')

plt.title("Model Comparison - Mean Squared Error (MSE)")
plt.xlabel("Model")
plt.ylabel("MSE")
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

# RMSE Bar Chart
plt.figure(figsize=(10, 5))
plt.bar(comparison_df.index, comparison_df['RMSE'], color='salmon', edgecolor='black')

# Add values on top
for i, v in enumerate(comparison_df['RMSE']):
    plt.text(i, v + 0.01 * v, f"{v:,.2f}", ha='center', va='bottom')

plt.title("Model Comparison - Root Mean Squared Error (RMSE)")
plt.xlabel("Model")
plt.ylabel("RMSE")
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Models and original R¬≤ scores
models = ['Linear Regression', 'SVR', 'Random Forest', 'XGBoost', 'CatBoost']
r2_scores_raw = [0.569, -2.015, 0.701, 0.486, 0.606]

# Step 1: Normalize R¬≤ scores to be positive for pie chart display
min_r2 = min(r2_scores_raw)
shift = abs(min_r2) + 0.1  # add small buffer
r2_scores_shifted = [r + shift for r in r2_scores_raw]

# Step 2: Highlight best model
best_index = r2_scores_raw.index(max(r2_scores_raw))  # Random Forest
explode = [0.1 if i == best_index else 0 for i in range(len(models))]
colors = ['lightblue', 'lightcoral', 'gold', 'violet', 'lightgreen']

# Step 3: Plot pie chart
plt.figure(figsize=(8, 8))
wedges, texts, autotexts = plt.pie(
    r2_scores_shifted,
    labels=models,
    explode=explode,
    colors=colors,
    shadow=True,
    startangle=140,
    autopct='%1.1f%%',
    textprops={'fontsize': 12}
)

# Add original R¬≤ scores to labels
for i, a in enumerate(autotexts):
    a.set_text(f"R¬≤: {r2_scores_raw[i]:.3f}\n({a.get_text()})")
    if i == best_index:
        texts[i].set_fontweight('bold')
        texts[i].set_color('darkgreen')
        a.set_fontweight('bold')
        a.set_color('darkgreen')

plt.title("Model Comparison (R¬≤ Score)\nüèÜ Random Forest Highlighted", fontsize=14)
plt.tight_layout()
plt.show()

# Convert y_test and predictions to numeric (just in case)
y_test_series = pd.Series(y_test).reset_index(drop=True).astype(float)
y_pred_rf_series = pd.Series(y_pred_rf).reset_index(drop=True).astype(float)

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd

# Ensure numeric types
y_test_series = pd.Series(y_test).reset_index(drop=True).astype(float)
y_pred_rf_series = pd.Series(y_pred_rf).reset_index(drop=True).astype(float)

# Plot
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test_series, y=y_pred_rf_series, color='teal', alpha=0.6, edgecolor=None)

# Ideal prediction line
plt.plot([y_test_series.min(), y_test_series.max()],
         [y_test_series.min(), y_test_series.max()],
         color='red', linestyle='--', linewidth=2, label='Ideal: y = x')

# Labels and title
plt.xlabel('Actual Rent')
plt.ylabel('Predicted Rent')
plt.title('Actual vs Predicted Rent (Random Forest)')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)

# Limit number of x-axis ticks
plt.xticks(np.linspace(y_test_series.min(), y_test_series.max(), 10))

plt.tight_layout()
plt.show()

y_pred_lin_series = pd.Series(y_pred_lin).reset_index(drop=True).astype(float)

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test_series, y=y_pred_lin_series, color='dodgerblue', alpha=0.6)
plt.plot([y_test_series.min(), y_test_series.max()],
         [y_test_series.min(), y_test_series.max()],
         color='red', linestyle='--', linewidth=2, label='Ideal: y = x')

plt.xlabel('Actual Rent')
plt.ylabel('Predicted Rent')
plt.title('Actual vs Predicted Rent (Linear Regression)')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)
plt.xticks(np.linspace(y_test_series.min(), y_test_series.max(), 10))
plt.tight_layout()
plt.show()

y_pred_svr_series = pd.Series(y_pred_svr).reset_index(drop=True).astype(float)

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test_series, y=y_pred_svr_series, color='orchid', alpha=0.6)
plt.plot([y_test_series.min(), y_test_series.max()],
         [y_test_series.min(), y_test_series.max()],
         color='red', linestyle='--', linewidth=2, label='Ideal: y = x')

plt.xlabel('Actual Rent')
plt.ylabel('Predicted Rent')
plt.title('Actual vs Predicted Rent (SVR)')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)
plt.xticks(np.linspace(y_test_series.min(), y_test_series.max(), 10))
plt.tight_layout()
plt.show()

y_pred_xgb_series = pd.Series(y_pred_xgb).reset_index(drop=True).astype(float)

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test_series, y=y_pred_xgb_series, color='darkorange', alpha=0.6)
plt.plot([y_test_series.min(), y_test_series.max()],
         [y_test_series.min(), y_test_series.max()],
         color='red', linestyle='--', linewidth=2, label='Ideal: y = x')

plt.xlabel('Actual Rent')
plt.ylabel('Predicted Rent')
plt.title('Actual vs Predicted Rent (XGBoost)')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)
plt.xticks(np.linspace(y_test_series.min(), y_test_series.max(), 10))
plt.tight_layout()
plt.show()

y_pred_cat_series = pd.Series(y_pred_cat).reset_index(drop=True).astype(float)

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test_series, y=y_pred_cat_series, color='mediumseagreen', alpha=0.6)
plt.plot([y_test_series.min(), y_test_series.max()],
         [y_test_series.min(), y_test_series.max()],
         color='red', linestyle='--', linewidth=2, label='Ideal: y = x')

plt.xlabel('Actual Rent')
plt.ylabel('Predicted Rent')
plt.title('Actual vs Predicted Rent (CatBoost)')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)
plt.xticks(np.linspace(y_test_series.min(), y_test_series.max(), 10))
plt.tight_layout()
plt.show()