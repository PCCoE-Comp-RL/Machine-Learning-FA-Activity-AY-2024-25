{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e055a222-87f9-4d0e-bc8d-ca0836979664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the path to your dataset using raw string\n",
    "dataset_path = r'C:\\Users\\Arya\\Desktop\\Bengaluru_House_Data.csv'\n",
    "# Load the dataset\n",
    "df = pd.read_csv(dataset_path)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4709e620-de93-4719-83f3-a6a888b081b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (13320, 9)\n",
      "\n",
      "First few rows:\n",
      "              area_type   availability                  location       size  \\\n",
      "0  Super built-up  Area         19-Dec  Electronic City Phase II      2 BHK   \n",
      "1            Plot  Area  Ready To Move          Chikka Tirupathi  4 Bedroom   \n",
      "2        Built-up  Area  Ready To Move               Uttarahalli      3 BHK   \n",
      "3  Super built-up  Area  Ready To Move        Lingadheeranahalli      3 BHK   \n",
      "4  Super built-up  Area  Ready To Move                  Kothanur      2 BHK   \n",
      "\n",
      "   society total_sqft  bath  balcony   price  \n",
      "0  Coomee        1056   2.0      1.0   39.07  \n",
      "1  Theanmp       2600   5.0      3.0  120.00  \n",
      "2      NaN       1440   2.0      3.0   62.00  \n",
      "3  Soiewre       1521   3.0      1.0   95.00  \n",
      "4      NaN       1200   2.0      1.0   51.00  \n",
      "\n",
      "Available columns:\n",
      "['area_type', 'availability', 'location', 'size', 'society', 'total_sqft', 'bath', 'balcony', 'price']\n",
      "\n",
      "Missing values before preprocessing:\n",
      "area_type          0\n",
      "availability       0\n",
      "location           1\n",
      "size              16\n",
      "society         5502\n",
      "total_sqft         0\n",
      "bath              73\n",
      "balcony          609\n",
      "price              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    " \n",
    "    # Data preprocessing\n",
    "    print(\"Dataset Shape:\", df.shape)\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Print column names to see what's available\n",
    "    print(\"\\nAvailable columns:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    # Handle missing values\n",
    "    print(\"\\nMissing values before preprocessing:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # Drop rows with missing values in price (target variable)\n",
    "    df = df.dropna(subset=['price'])\n",
    "    \n",
    "    # Fill missing values in other columns\n",
    "    df['size'] = df['size'].fillna(df['size'].mode()[0])\n",
    "    df['bath'] = df['bath'].fillna(df['bath'].median())\n",
    "    df['balcony'] = df['balcony'].fillna(df['balcony'].median())\n",
    "    \n",
    "    # Feature engineering\n",
    "    # Convert size to numeric if it's not already\n",
    "    if df['size'].dtype == 'object':\n",
    "        # Remove any non-numeric characters and convert to float\n",
    "        df['size'] = df['size'].str.replace(r'[^\\d.]', '', regex=True).astype(float)\n",
    "    else:\n",
    "        # If already numeric, ensure it's float type\n",
    "        df['size'] = df['size'].astype(float)\n",
    "    \n",
    "    # Create new features\n",
    "    df['price_per_sqft'] = df['price'] / df['size']\n",
    "    \n",
    "    # Drop unnecessary columns if they exist\n",
    "    columns_to_drop = ['society', 'availability']\n",
    "    existing_columns = [col for col in columns_to_drop if col in df.columns]\n",
    "    if existing_columns:\n",
    "        df = df.drop(existing_columns, axis=1)\n",
    "    \n",
    "    # Prepare data for modeling\n",
    "    X = df.drop('price', axis=1)\n",
    "    y = df['price']\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define numerical and categorical columns\n",
    "    numerical_cols = ['size', 'bath', 'balcony', 'price_per_sqft']\n",
    "    categorical_cols = ['area_type', 'location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b228cd3-938b-4ead-a766-8ca950f326c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipelines\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    # Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c5508f0-bdad-495f-b87e-ac924bfc0e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipelines\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "('imputer', SimpleImputer(strategy='median')),\n",
    "('scaler', StandardScaler())\n",
    "])\n",
    "    \n",
    "categorical_transformer = Pipeline(steps=[\n",
    "('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "    \n",
    "    # Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "('num', numerical_transformer, numerical_cols),\n",
    "('cat', categorical_transformer, categorical_cols)\n",
    "])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d96ca4-74fb-4e9c-9d0d-2530a54c3c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grids for each model\n",
    "param_grids = {\n",
    "        'Random Forest': {\n",
    "            'model__n_estimators': [100, 200, 300],\n",
    "            'model__max_depth': [None, 10, 20, 30],\n",
    "            'model__min_samples_split': [2, 5, 10],\n",
    "            'model__min_samples_leaf': [1, 2, 4]\n",
    "        },\n",
    "        'XGBoost': {\n",
    "            'model__n_estimators': [100, 200, 300],\n",
    "            'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "            'model__max_depth': [3, 5, 7],\n",
    "            'model__subsample': [0.8, 0.9, 1.0]\n",
    "        },\n",
    "        'SVR': {\n",
    "            'model__C': [0.1, 1, 10],\n",
    "            'model__kernel': ['linear', 'rbf'],\n",
    "            'model__gamma': ['scale', 'auto']\n",
    "        },\n",
    "        'Neural Network': {\n",
    "            'model__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "            'model__activation': ['relu', 'tanh'],\n",
    "            'model__alpha': [0.0001, 0.001, 0.01]\n",
    "        }\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd597556-4f8a-4729-a743-637162b02dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning Random Forest...\n",
      "\n",
      "Tuning XGBoost...\n",
      "\n",
      "Tuning SVR...\n",
      "\n",
      "Tuning Neural Network...\n"
     ]
    }
   ],
   "source": [
    " # Define base models\n",
    "base_models = {\n",
    "        'Random Forest': RandomForestRegressor(random_state=42),\n",
    "        'XGBoost': XGBRegressor(random_state=42),\n",
    "        'SVR': SVR(),\n",
    "        'Neural Network': MLPRegressor(random_state=42, max_iter=1000)\n",
    "    }\n",
    "    \n",
    "    # Train and evaluate models with hyperparameter tuning\n",
    "results = {}\n",
    "best_models = {}\n",
    "    \n",
    "for name, model in base_models.items():\n",
    "        print(f\"\\nTuning {name}...\")\n",
    "        \n",
    "        # Create pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                  ('model', model)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ad92c8-d0f9-4f98-8769-eda9dd336810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    }
   ],
   "source": [
    " # Create GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grids[name],\n",
    "            cv=5,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Store the best model\n",
    "best_models[name] = grid_search.best_estimator_\n",
    "        \n",
    "        # Make predictions\n",
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb36fa-6b5e-47ac-9251-de8b4a60fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        results[name] = {\n",
    "            'MSE': mse,\n",
    "            'RMSE': np.sqrt(mse),\n",
    "            'R2': r2,\n",
    "            'Best Parameters': grid_search.best_params_,\n",
    "            'Training Time (s)': time.time() - start_time\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{name} Results:\")\n",
    "        print(f\"  Best Parameters: {grid_search.best_params_}\")\n",
    "        print(f\"  MSE: {mse:.2f}\")\n",
    "        print(f\"  RMSE: {np.sqrt(mse):.2f}\")\n",
    "        print(f\"  R2 Score: {r2:.2f}\")\n",
    "        print(f\"  Training Time: {time.time() - start_time:.2f} seconds\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f20849-0265-4191-a205-85f594df8bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "    print(\"\\nCreating visualizations...\")\n",
    "    metrics_df = pd.DataFrame(results).T\n",
    "    \n",
    "    # Create a larger figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd86d13e-b611-4dd5-ab8f-44d3985ca316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bar plot\n",
    "    metrics_df['R2'].plot(kind='bar', color='skyblue')\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('R2 Scores for Different Models (After Hyperparameter Tuning)', fontsize=14, pad=20)\n",
    "    plt.ylabel('R2 Score', fontsize=12)\n",
    "    plt.xlabel('Models', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add value labels on top of each bar\n",
    "    for i, v in enumerate(metrics_df['R2']):\n",
    "        plt.text(i, v, f'{v:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Adjust layout to prevent label cutoff\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa2234-37c5-47a8-bf32-ea8d51a3ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Print detailed results\n",
    "    print(\"\\nDetailed Results:\")\n",
    "    print(metrics_df)\n",
    "    \n",
    "    # Print best parameters for each model\n",
    "    print(\"\\nBest Parameters for Each Model:\")\n",
    "    for name, result in results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(result['Best Parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd7de00-e5c1-4f48-b80c-24003d9798e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd51314e-8d9c-4e91-9206-b1472b64bb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e78ab2-aafe-480a-8376-0e08eda4ddb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181c7eff-901b-474d-85ba-0f9e9a74933d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880431ed-3e2f-4905-a3a0-15ebc15ba06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16026c6-3d9d-45ab-9baf-806b455ff2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
